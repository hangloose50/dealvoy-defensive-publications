#!/usr/bin/env python3
"""
SOURCE_EXPANSION_PHASE_1 Test Suite
Tests the enhanced retail scraper system with 50+ sources
"""

import os
import sys
import json
import time
from typing import Dict, List, Any

# Add current directory to path
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)

# Import our components
try:
    from RetailScraperBase import RetailScraperBase, ProductData
    from scraper_registry import ScraperRegistry, search_products, get_available_sources, get_registry_info
    from target_scraper import scrape_target, TargetScraper
    from bestbuy_scraper import scrape_bestbuy, BestBuyScraper
    from cvs_scraper import scrape_cvs, CVSScraper
    from homedepot_scraper import scrape_homedepot, HomeDepotScraper
    from lowes_scraper import scrape_lowes, LowesScraper
except ImportError as e:
    print(f"‚ùå Import error: {e}")
    print("üîÑ Some scrapers may not be fully implemented yet")

def test_base_scraper():
    """Test the RetailScraperBase foundation"""
    print("üß™ Testing RetailScraperBase...")
    
    # Test basic initialization
    base_scraper = RetailScraperBase("TestSource", "https://example.com")
    
    # Test price extraction
    test_prices = ["$19.99", "$1,299.00", "Price: $45.50", "‚Ç¨29.99", "¬£15.00"]
    for price_text in test_prices:
        extracted = base_scraper.extract_price(price_text)
        print(f"  '{price_text}' ‚Üí ${extracted}")
    
    # Test UPC extraction
    test_upcs = [
        "UPC: 123456789012",
        "Product code 987654321098",
        "GTIN: 111222333444",
        "Barcode: 555666777888"
    ]
    for upc_text in test_upcs:
        extracted = base_scraper.extract_upc(upc_text)
        print(f"  '{upc_text}' ‚Üí {extracted}")
    
    print("‚úÖ RetailScraperBase tests passed")

def test_individual_scrapers():
    """Test individual scraper modules"""
    print("\nüß™ Testing Individual Scrapers...")
    
    # Test data for each scraper
    test_cases = [
        {
            'name': 'Target',
            'scraper_class': TargetScraper,
            'function': scrape_target,
            'query': 'electronics',
            'expected_source': 'Target'
        },
        {
            'name': 'BestBuy',
            'scraper_class': BestBuyScraper,
            'function': scrape_bestbuy,
            'query': 'laptop',
            'expected_source': 'BestBuy'
        },
        {
            'name': 'CVS',
            'scraper_class': CVSScraper,
            'function': scrape_cvs,
            'query': 'vitamins',
            'expected_source': 'CVS'
        },
        {
            'name': 'HomeDepot',
            'scraper_class': HomeDepotScraper,
            'function': scrape_homedepot,
            'query': 'tools',
            'expected_source': 'HomeDepot'
        },
        {
            'name': 'Lowes',
            'scraper_class': LowesScraper,
            'function': scrape_lowes,
            'query': 'appliances',
            'expected_source': 'Lowes'
        },
        # New batch for expansion
        {
            'name': 'FoodLion',
            'scraper_class': None,  # To be imported below
            'function': None,
            'query': 'milk',
            'expected_source': 'Food Lion'
        },
        {
            'name': 'Giant',
            'scraper_class': None,
            'function': None,
            'query': 'bread',
            'expected_source': 'Giant Food'
        },
        {
            'name': 'WorldMarket',
            'scraper_class': None,
            'function': None,
            'query': 'coffee',
            'expected_source': 'Cost Plus World Market'
        }
    ]

    # Import new scrapers for test cases
    try:
        from foodlion_scraper import FoodLionScraper
        from giant_scraper import GiantScraper
        from worldmarket_scraper import WorldMarketScraper
        from foodlion_scraper import scrape_foodlion
        from giant_scraper import scrape_giant
        from worldmarket_scraper import scrape_worldmarket
        # Patch test cases with actual classes/functions
        for tc in test_cases:
            if tc['name'] == 'FoodLion':
                tc['scraper_class'] = FoodLionScraper
                tc['function'] = scrape_foodlion
            elif tc['name'] == 'Giant':
                tc['scraper_class'] = GiantScraper
                tc['function'] = scrape_giant
            elif tc['name'] == 'WorldMarket':
                tc['scraper_class'] = WorldMarketScraper
                tc['function'] = scrape_worldmarket
    except Exception as e:
        print(f"‚ö†Ô∏è Could not import new batch scrapers: {e}")
    
    results = []
    
    for test_case in test_cases:
        print(f"\n  üéØ Testing {test_case['name']}...")
        
        try:
            # Test class initialization
            scraper = test_case['scraper_class']()
            print(f"    ‚úÖ {test_case['name']} scraper initialized")
            
            # Test compliance check (without actual web request)
            compliance_check = scraper.robots_checker is not None
            print(f"    ‚úÖ Compliance framework: {'‚úì' if compliance_check else '‚úó'}")
            
            # Test function availability
            func_available = callable(test_case['function'])
            print(f"    ‚úÖ Scraper function: {'‚úì' if func_available else '‚úó'}")
            
            results.append({
                'name': test_case['name'],
                'initialized': True,
                'compliance': compliance_check,
                'function': func_available,
                'status': 'READY'
            })
            
        except Exception as e:
            print(f"    ‚ùå {test_case['name']} error: {str(e)}")
            results.append({
                'name': test_case['name'],
                'initialized': False,
                'compliance': False,
                'function': False,
                'status': 'ERROR',
                'error': str(e)
            })
    
    return results

def test_scraper_registry():
    """Test the centralized scraper registry"""
    print("\nüß™ Testing Scraper Registry...")
    
    try:
        # Test registry initialization
        registry = ScraperRegistry()
        print("    ‚úÖ Registry initialized")
        
        # Test available sources
        sources = get_available_sources()
        print(f"    ‚úÖ Available sources: {len(sources)}")
        
        # Test registry info
        info = get_registry_info()
        print(f"    ‚úÖ Total scrapers: {info['total_scrapers']}")
        print(f"    ‚úÖ Categories: {len(info['categories'])}")
        
        # Test categories
        for category, count in info['category_counts'].items():
            print(f"      üìÇ {category}: {count} scrapers")
        
        return {
            'initialized': True,
            'total_scrapers': info['total_scrapers'],
            'categories': len(info['categories']),
            'status': 'READY'
        }
        
    except Exception as e:
        print(f"    ‚ùå Registry error: {str(e)}")
        return {
            'initialized': False,
            'status': 'ERROR',
            'error': str(e)
        }

def test_compliance_framework():
    """Test robots.txt compliance and rate limiting"""
    print("\nüß™ Testing Compliance Framework...")
    
    try:
        # Test with Target scraper
        scraper = TargetScraper()
        
        # Test robots.txt checker
        robots_available = scraper.robots_checker is not None
        print(f"    ‚úÖ Robots.txt checker: {'‚úì' if robots_available else '‚úó'}")
        
        # Test rate limiting
        rate_limit_available = hasattr(scraper, 'rate_limit')
        print(f"    ‚úÖ Rate limiting: {'‚úì' if rate_limit_available else '‚úó'}")
        
        # Test user agent rotation
        user_agent_available = len(scraper.user_agents) > 1
        print(f"    ‚úÖ User agent rotation: {'‚úì' if user_agent_available else '‚úó'}")
        
        # Test anti-bot features
        anti_bot_available = hasattr(scraper, 'get_driver')
        print(f"    ‚úÖ Anti-bot features: {'‚úì' if anti_bot_available else '‚úó'}")
        
        return {
            'robots_txt': robots_available,
            'rate_limiting': rate_limit_available,
            'user_agent_rotation': user_agent_available,
            'anti_bot': anti_bot_available,
            'status': 'COMPLIANT'
        }
        
    except Exception as e:
        print(f"    ‚ùå Compliance error: {str(e)}")
        return {
            'status': 'ERROR',
            'error': str(e)
        }

def test_product_data_structure():
    """Test ProductData standardization"""
    print("\nüß™ Testing ProductData Structure...")
    
    try:
        # Create sample product data
        product = ProductData(
            title="Test Product",
            price=29.99,
            in_stock=True,
            product_url="https://example.com/product",
            image_url="https://example.com/image.jpg",
            upc="123456789012",
            sku="TEST-SKU-001",
            source="TestSource",
            brand="TestBrand"
        )
        
        # Test all required fields
        required_fields = ['title', 'price', 'in_stock', 'product_url', 'source']
        missing_fields = []
        
        for field in required_fields:
            if not hasattr(product, field):
                missing_fields.append(field)
        
        if missing_fields:
            print(f"    ‚ùå Missing fields: {missing_fields}")
            return {'status': 'ERROR', 'missing_fields': missing_fields}
        else:
            print("    ‚úÖ All required fields present")
            print(f"    ‚úÖ Product: {product.title}")
            print(f"    ‚úÖ Price: ${product.price}")
            print(f"    ‚úÖ Source: {product.source}")
            
            return {
                'status': 'VALID',
                'fields_count': len(product.__dict__),
                'sample_product': product.title
            }
        
    except Exception as e:
        print(f"    ‚ùå ProductData error: {str(e)}")
        return {
            'status': 'ERROR',
            'error': str(e)
        }

def generate_test_report():
    """Generate comprehensive test report"""
    print("üöÄ SOURCE_EXPANSION_PHASE_1 Test Suite")
    print("=" * 60)
    
    # Run all tests
    test_results = {
        'timestamp': time.time(),
        'base_scraper': test_base_scraper(),
        'individual_scrapers': test_individual_scrapers(),
        'scraper_registry': test_scraper_registry(),
        'compliance_framework': test_compliance_framework(),
        'product_data': test_product_data_structure()
    }
    
    # Calculate overall status
    print("\nüìä TEST SUMMARY")
    print("=" * 40)
    
    total_tests = 0
    passed_tests = 0
    
    # Base scraper (always passes if no exception)
    total_tests += 1
    passed_tests += 1
    print("‚úÖ RetailScraperBase: PASSED")
    
    # Individual scrapers
    for scraper_result in test_results['individual_scrapers']:
        total_tests += 1
        if scraper_result['status'] == 'READY':
            passed_tests += 1
            print(f"‚úÖ {scraper_result['name']} Scraper: PASSED")
        else:
            print(f"‚ùå {scraper_result['name']} Scraper: FAILED")
    
    # Registry
    total_tests += 1
    if test_results['scraper_registry']['status'] == 'READY':
        passed_tests += 1
        print("‚úÖ Scraper Registry: PASSED")
    else:
        print("‚ùå Scraper Registry: FAILED")
    
    # Compliance
    total_tests += 1
    if test_results['compliance_framework']['status'] == 'COMPLIANT':
        passed_tests += 1
        print("‚úÖ Compliance Framework: PASSED")
    else:
        print("‚ùå Compliance Framework: FAILED")
    
    # Product data
    total_tests += 1
    if test_results['product_data']['status'] == 'VALID':
        passed_tests += 1
        print("‚úÖ ProductData Structure: PASSED")
    else:
        print("‚ùå ProductData Structure: FAILED")
    
    # Overall results
    success_rate = (passed_tests / total_tests) * 100
    print(f"\nüéØ OVERALL RESULTS: {passed_tests}/{total_tests} tests passed ({success_rate:.1f}%)")
    
    if success_rate >= 80:
        print("‚úÖ SOURCE_EXPANSION_PHASE_1: READY FOR DEPLOYMENT")
        status = "READY"
    elif success_rate >= 60:
        print("‚ö†Ô∏è SOURCE_EXPANSION_PHASE_1: NEEDS MINOR FIXES")
        status = "PARTIAL"
    else:
        print("‚ùå SOURCE_EXPANSION_PHASE_1: NEEDS MAJOR FIXES")
        status = "FAILED"
    
    # Add summary to results
    test_results['summary'] = {
        'total_tests': total_tests,
        'passed_tests': passed_tests,
        'success_rate': success_rate,
        'overall_status': status
    }
    
    # Save test report
    report_path = os.path.join(current_dir, '../source_expansion_test_report.json')
    try:
        with open(report_path, 'w') as f:
            json.dump(test_results, f, indent=2, default=str)
        print(f"\nüìÑ Test report saved: {report_path}")
    except Exception as e:
        print(f"‚ö†Ô∏è Could not save test report: {e}")
    
    return test_results

if __name__ == "__main__":
    # Run the complete test suite
    results = generate_test_report()
    
    # Print final status
    print(f"\nüèÅ Testing complete!")
    if results['summary']['overall_status'] == 'READY':
        print("üéâ System ready for 50+ source expansion!")
    else:
        print("üîß System needs fixes before full deployment")
