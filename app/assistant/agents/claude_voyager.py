#!/usr/bin/env python3
"""
ðŸ§  ClaudeVoyager - Uses Claude for flow planning and intelligent analysis
Coordinates with GPT for hybrid AI workflows and provides strategic insights
"""

import os
import json
import hashlib
from datetime import datetime
from pathlib import Path

class ClaudeVoyager:
    def __init__(self, project_path="."):
        self.project_path = Path(project_path)
        self.insights_dir = self.project_path / "claude_insights"
        self.insights_dir.mkdir(parents=True, exist_ok=True)
        self.analysis_cache = {}
        
    def analyze_project_structure(self):
        """Analyze project for strategic insights"""
        structure_analysis = {
            "timestamp": datetime.now().isoformat(),
            "project_type": "dealvoy_ecosystem",
            "components": [],
            "complexity_score": 0,
            "recommendations": []
        }
        
        # Analyze directory structure
        key_directories = ["app", "tests", "scripts", "app_shell"]
        for dir_name in key_directories:
            dir_path = self.project_path / dir_name
            if dir_path.exists():
                component_analysis = self._analyze_component(dir_path)
                structure_analysis["components"].append(component_analysis)
                structure_analysis["complexity_score"] += component_analysis["complexity"]
                
        # Generate strategic recommendations
        structure_analysis["recommendations"] = self._generate_strategic_recommendations(
            structure_analysis["components"], 
            structure_analysis["complexity_score"]
        )
        
        return structure_analysis
    
    def _analyze_component(self, component_path):
        """Analyze individual component complexity and purpose"""
        component_info = {
            "name": component_path.name,
            "type": self._classify_component(component_path),
            "file_count": 0,
            "python_files": 0,
            "test_files": 0,
            "complexity": 0,
            "key_patterns": []
        }
        
        # Count files and analyze patterns
        for file_path in component_path.rglob("*"):
            if file_path.is_file():
                component_info["file_count"] += 1
                
                if file_path.suffix == ".py":
                    component_info["python_files"] += 1
                    
                    if "test_" in file_path.name:
                        component_info["test_files"] += 1
                    
                    # Analyze file content for patterns
                    patterns = self._detect_patterns_in_file(file_path)
                    component_info["key_patterns"].extend(patterns)
                    
        # Calculate complexity score
        component_info["complexity"] = (
            component_info["python_files"] * 2 + 
            len(component_info["key_patterns"]) +
            (10 if component_info["name"] == "app" else 5)
        )
        
        return component_info
    
    def _classify_component(self, path):
        """Classify component type for strategic analysis"""
        name = path.name.lower()
        
        if name == "app":
            return "core_application"
        elif name == "tests":
            return "testing_framework"
        elif name == "scripts":
            return "automation_tools"
        elif "shell" in name:
            return "ui_framework"
        elif name == "services":
            return "service_layer"
        else:
            return "support_module"
    
    def _detect_patterns_in_file(self, file_path):
        """Detect important patterns in Python files"""
        patterns = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
                # Detect key patterns
                if "class " in content and "def " in content:
                    patterns.append("object_oriented_design")
                    
                if "async def" in content:
                    patterns.append("async_programming")
                    
                if "from fastapi" in content or "from flask" in content:
                    patterns.append("web_framework")
                    
                if "import pytest" in content or "def test_" in content:
                    patterns.append("testing_implementation")
                    
                if "scraper" in content.lower():
                    patterns.append("data_scraping")
                    
                if "openai" in content.lower() or "claude" in content.lower():
                    patterns.append("ai_integration")
                    
                if "camera" in content.lower() or "ocr" in content.lower():
                    patterns.append("computer_vision")
                    
        except Exception:
            pass
            
        return patterns
    
    def _generate_strategic_recommendations(self, components, complexity_score):
        """Generate high-level strategic recommendations"""
        recommendations = []
        
        # Complexity-based recommendations
        if complexity_score > 100:
            recommendations.append({
                "type": "architecture",
                "priority": "high",
                "title": "Consider Modularization",
                "description": "High complexity detected. Consider breaking into microservices or modules.",
                "impact": "maintainability"
            })
            
        # Component-specific recommendations
        has_tests = any(c["test_files"] > 0 for c in components)
        if not has_tests:
            recommendations.append({
                "type": "quality",
                "priority": "high", 
                "title": "Implement Testing Strategy",
                "description": "No test files detected. Add comprehensive test coverage.",
                "impact": "reliability"
            })
            
        # Pattern-based recommendations
        all_patterns = []
        for component in components:
            all_patterns.extend(component["key_patterns"])
            
        if "ai_integration" in all_patterns and "async_programming" not in all_patterns:
            recommendations.append({
                "type": "performance",
                "priority": "medium",
                "title": "Implement Async AI Calls",
                "description": "AI integrations detected. Consider async patterns for better performance.",
                "impact": "user_experience"
            })
            
        if "data_scraping" in all_patterns and "computer_vision" in all_patterns:
            recommendations.append({
                "type": "integration",
                "priority": "medium",
                "title": "Unified Data Pipeline",
                "description": "Multiple data sources detected. Consider unified data processing pipeline.",
                "impact": "efficiency"
            })
            
        return recommendations
    
    def create_flow_chart(self, workflow_type="user_journey"):
        """Create flow chart analysis for different workflow types"""
        flow_charts = {
            "user_journey": self._create_user_journey_flow(),
            "data_processing": self._create_data_processing_flow(),
            "ai_workflow": self._create_ai_workflow_flow(),
            "deployment": self._create_deployment_flow()
        }
        
        return flow_charts.get(workflow_type, {})
    
    def _create_user_journey_flow(self):
        """Create user journey flow chart"""
        return {
            "title": "Dealvoy User Journey",
            "type": "user_flow",
            "nodes": [
                {"id": "start", "label": "User Opens App", "type": "start"},
                {"id": "scan", "label": "Scan Product", "type": "action"},
                {"id": "ocr", "label": "OCR Processing", "type": "process"},
                {"id": "identify", "label": "Product Identification", "type": "process"},
                {"id": "search", "label": "Price Search", "type": "process"},
                {"id": "compare", "label": "Price Comparison", "type": "process"},
                {"id": "results", "label": "Show Results", "type": "output"},
                {"id": "save", "label": "Save Deal", "type": "action"},
                {"id": "end", "label": "User Exits", "type": "end"}
            ],
            "edges": [
                {"from": "start", "to": "scan"},
                {"from": "scan", "to": "ocr"},
                {"from": "ocr", "to": "identify"},
                {"from": "identify", "to": "search"},
                {"from": "search", "to": "compare"},
                {"from": "compare", "to": "results"},
                {"from": "results", "to": "save"},
                {"from": "save", "to": "end"}
            ],
            "critical_path": ["start", "scan", "ocr", "identify", "search", "compare", "results"]
        }
    
    def _create_data_processing_flow(self):
        """Create data processing flow chart"""
        return {
            "title": "Data Processing Pipeline",
            "type": "data_flow",
            "nodes": [
                {"id": "input", "label": "Product Image/Text", "type": "input"},
                {"id": "ocr", "label": "OCR Extraction", "type": "process"},
                {"id": "clean", "label": "Data Cleaning", "type": "process"},
                {"id": "identify", "label": "Product Matching", "type": "process"},
                {"id": "scrape", "label": "Price Scraping", "type": "process"},
                {"id": "analyze", "label": "Deal Analysis", "type": "process"},
                {"id": "store", "label": "Data Storage", "type": "storage"},
                {"id": "output", "label": "Results", "type": "output"}
            ],
            "edges": [
                {"from": "input", "to": "ocr"},
                {"from": "ocr", "to": "clean"},
                {"from": "clean", "to": "identify"},
                {"from": "identify", "to": "scrape"},
                {"from": "scrape", "to": "analyze"},
                {"from": "analyze", "to": "store"},
                {"from": "analyze", "to": "output"}
            ]
        }
    
    def _create_ai_workflow_flow(self):
        """Create AI workflow flow chart"""
        return {
            "title": "AI Processing Workflow",
            "type": "ai_flow",
            "nodes": [
                {"id": "prompt", "label": "Prompt Generation", "type": "ai"},
                {"id": "gpt", "label": "GPT-4 Processing", "type": "ai"},
                {"id": "claude", "label": "Claude Analysis", "type": "ai"},
                {"id": "merge", "label": "Result Synthesis", "type": "process"},
                {"id": "validate", "label": "Validation", "type": "process"},
                {"id": "output", "label": "Final Output", "type": "output"}
            ],
            "edges": [
                {"from": "prompt", "to": "gpt"},
                {"from": "prompt", "to": "claude"},
                {"from": "gpt", "to": "merge"},
                {"from": "claude", "to": "merge"},
                {"from": "merge", "to": "validate"},
                {"from": "validate", "to": "output"}
            ]
        }
    
    def _create_deployment_flow(self):
        """Create deployment workflow"""
        return {
            "title": "Deployment Pipeline",
            "type": "deployment_flow",
            "nodes": [
                {"id": "code", "label": "Code Commit", "type": "start"},
                {"id": "test", "label": "Run Tests", "type": "process"},
                {"id": "build", "label": "Build App", "type": "process"},
                {"id": "staging", "label": "Deploy Staging", "type": "deployment"},
                {"id": "validate", "label": "Validation Tests", "type": "process"},
                {"id": "production", "label": "Deploy Production", "type": "deployment"},
                {"id": "monitor", "label": "Monitor", "type": "monitoring"}
            ],
            "edges": [
                {"from": "code", "to": "test"},
                {"from": "test", "to": "build"},
                {"from": "build", "to": "staging"},
                {"from": "staging", "to": "validate"},
                {"from": "validate", "to": "production"},
                {"from": "production", "to": "monitor"}
            ]
        }
    
    def generate_task_breakdown(self, high_level_goal):
        """Break down high-level goals into actionable tasks"""
        task_breakdowns = {
            "scoutvision_ocr": self._breakdown_scoutvision_ocr(),
            "app_deployment": self._breakdown_app_deployment(),
            "testing_enhancement": self._breakdown_testing_enhancement(),
            "performance_optimization": self._breakdown_performance_optimization()
        }
        
        return task_breakdowns.get(high_level_goal, {})
    
    def _breakdown_scoutvision_ocr(self):
        """Break down ScoutVision OCR implementation"""
        return {
            "goal": "Implement ScoutVision OCR Integration",
            "phases": [
                {
                    "phase": "1. Foundation",
                    "tasks": [
                        "Install Tesseract and OpenCV dependencies",
                        "Set up camera access permissions",
                        "Create base OCR processing class",
                        "Implement image preprocessing pipeline"
                    ],
                    "estimated_hours": 8
                },
                {
                    "phase": "2. Core OCR",
                    "tasks": [
                        "Integrate Tesseract OCR engine",
                        "Implement text extraction and cleaning",
                        "Add barcode/UPC detection",
                        "Create confidence scoring system"
                    ],
                    "estimated_hours": 12
                },
                {
                    "phase": "3. Product Recognition",
                    "tasks": [
                        "Implement product matching logic",
                        "Connect to existing scraper registry",
                        "Add price lookup integration",
                        "Create result validation system"
                    ],
                    "estimated_hours": 10
                },
                {
                    "phase": "4. Testing & Polish",
                    "tasks": [
                        "Create comprehensive test suite",
                        "Add error handling and fallbacks",
                        "Optimize performance for mobile",
                        "Document API and usage"
                    ],
                    "estimated_hours": 6
                }
            ],
            "total_estimated_hours": 36,
            "dependencies": ["camera_permissions", "tesseract_installation", "existing_scrapers"],
            "success_criteria": [
                "OCR accuracy > 85% on product labels",
                "Processing time < 3 seconds per image",
                "Successful product identification > 70%",
                "Robust error handling for edge cases"
            ]
        }
    
    def _breakdown_app_deployment(self):
        """Break down app deployment process"""
        return {
            "phases": [
                {
                    "phase": "pre_deployment",
                    "tasks": ["Run test suite", "Security scan", "Performance check"],
                    "estimated_hours": 4
                },
                {
                    "phase": "build_process",
                    "tasks": ["Build for target platform", "Code signing", "Asset optimization"],
                    "estimated_hours": 6
                },
                {
                    "phase": "deployment",
                    "tasks": ["Deploy to staging", "Health checks", "Production deployment"],
                    "estimated_hours": 8
                }
            ],
            "total_estimated_hours": 18,
            "dependencies": ["test_passing", "certificates", "deployment_keys"],
            "success_criteria": ["All tests pass", "Zero critical vulnerabilities", "Performance within SLA"]
        }
    
    def _breakdown_testing_enhancement(self):
        """Break down testing improvements"""
        return {
            "phases": [
                {
                    "phase": "test_infrastructure",
                    "tasks": ["Setup CI/CD", "Test data management", "Mock services"],
                    "estimated_hours": 12
                },
                {
                    "phase": "test_coverage",
                    "tasks": ["Unit tests", "Integration tests", "E2E tests"],
                    "estimated_hours": 16
                },
                {
                    "phase": "test_automation",
                    "tasks": ["Automated regression", "Performance testing", "Security testing"],
                    "estimated_hours": 10
                }
            ],
            "total_estimated_hours": 38,
            "dependencies": ["testing_framework", "test_environment", "test_data"],
            "success_criteria": ["90%+ code coverage", "Automated test execution", "Fast feedback loops"]
        }
    
    def _breakdown_performance_optimization(self):
        """Break down performance optimization tasks"""
        return {
            "phases": [
                {
                    "phase": "profiling",
                    "tasks": ["Performance profiling", "Memory analysis", "Network optimization"],
                    "estimated_hours": 8
                },
                {
                    "phase": "optimization",
                    "tasks": ["Code optimization", "Database tuning", "Caching strategy"],
                    "estimated_hours": 14
                },
                {
                    "phase": "monitoring",
                    "tasks": ["Performance monitoring", "Alerting setup", "Dashboard creation"],
                    "estimated_hours": 6
                }
            ],
            "total_estimated_hours": 28,
            "dependencies": ["profiling_tools", "monitoring_infrastructure", "baseline_metrics"],
            "success_criteria": ["50% performance improvement", "Real-time monitoring", "Proactive alerts"]
        }
    
    def run(self):
        """Main execution function"""
        print("ðŸ§  [ClaudeVoyager] Analyzing project for strategic insights...")
        
        # Analyze project structure
        structure_analysis = self.analyze_project_structure()
        
        # Create flow charts
        flow_charts = {}
        for flow_type in ["user_journey", "data_processing", "ai_workflow", "deployment"]:
            flow_charts[flow_type] = self.create_flow_chart(flow_type)
            
        # Generate task breakdown for ScoutVision OCR
        scoutvision_breakdown = self.generate_task_breakdown("scoutvision_ocr")
        
        # Save comprehensive analysis
        analysis_file = self.insights_dir / f"claude_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        comprehensive_analysis = {
            "metadata": {
                "generated_at": datetime.now().isoformat(),
                "voyager": "claude_voyager",
                "version": "1.0.0"
            },
            "project_structure": structure_analysis,
            "flow_charts": flow_charts,
            "task_breakdowns": {
                "scoutvision_ocr": scoutvision_breakdown
            },
            "strategic_summary": {
                "complexity_level": "moderate" if structure_analysis["complexity_score"] < 80 else "high",
                "development_priority": "scoutvision_integration",
                "risk_factors": self._assess_risk_factors(structure_analysis),
                "success_probability": self._calculate_success_probability(structure_analysis)
            }
        }
        
        with open(analysis_file, 'w') as f:
            json.dump(comprehensive_analysis, f, indent=2)
            
        # Print executive summary
        print("âœ… ClaudeVoyager: Strategic analysis complete!")
        print(f"   ðŸ“Š Project Complexity: {structure_analysis['complexity_score']} points")
        print(f"   ðŸŽ¯ Priority Recommendations: {len(structure_analysis['recommendations'])}")
        print(f"   ðŸ“ˆ Success Probability: {comprehensive_analysis['strategic_summary']['success_probability']}%")
        print(f"   ðŸ“„ Full Analysis: {analysis_file}")
        
        # Print top recommendations
        if structure_analysis['recommendations']:
            print("\nðŸŽ¯ Top Strategic Recommendations:")
            for rec in structure_analysis['recommendations'][:3]:
                print(f"   {rec['priority'].upper()}: {rec['title']}")
                print(f"      {rec['description']}")
                
        print("ðŸ§  [ClaudeVoyager] Ready for strategic planning coordination!")
    
    def _assess_risk_factors(self, analysis):
        """Assess project risk factors"""
        risks = []
        
        if analysis["complexity_score"] > 100:
            risks.append("high_complexity")
            
        test_coverage = any(c["test_files"] > 0 for c in analysis["components"])
        if not test_coverage:
            risks.append("low_test_coverage")
            
        ai_components = sum(1 for c in analysis["components"] 
                           if "ai_integration" in c["key_patterns"])
        if ai_components > 2:
            risks.append("ai_dependency")
            
        return risks
    
    def _calculate_success_probability(self, analysis):
        """Calculate project success probability"""
        base_score = 70
        
        # Adjust based on complexity
        if analysis["complexity_score"] > 100:
            base_score -= 15
        elif analysis["complexity_score"] < 50:
            base_score += 10
            
        # Adjust based on test coverage
        has_tests = any(c["test_files"] > 0 for c in analysis["components"])
        if has_tests:
            base_score += 15
        else:
            base_score -= 20
            
        # Adjust based on patterns
        all_patterns = []
        for component in analysis["components"]:
            all_patterns.extend(component["key_patterns"])
            
        if "testing_implementation" in all_patterns:
            base_score += 10
        if "object_oriented_design" in all_patterns:
            base_score += 5
        if "async_programming" in all_patterns:
            base_score += 5
            
        return max(10, min(95, base_score))

def run():
    """CLI entry point"""
    voyager = ClaudeVoyager()
    voyager.run()

if __name__ == "__main__":
    run()
